---
#title: "Clustering"
#date: "`r Sys.Date()`"
output:
  html_document:
    toc : true
    toc_float: true 
    toc_depth: 3
---

```{r setup, include = FALSE} 
knitr::opts_chunk$set(
  fig.width=9, fig.height=6,
  echo = FALSE,
  collapse = TRUE,
  comment = "#>"
)
#library(VIM)
library(tidyverse)
library(ggplot2)
library(plotly)
library(scales)
library(sendis)
library(stats)
library(kableExtra)
#library(factoextra)
library(randomForest)
library(rattle)
library(rpart)
library(rpart.plot)
library(splitstackshape)
library(data.table)

```

<br>

# Machine learning examples

## Principal Component Analysis 

Principal component analysis methods (PCA) are commonly used dimensionality reduction techniques that transform a collection of correlated variables into a smaller number of uncorrelated variables (or features) called *principal components*. Principal components are linear combinations of the original variables that account for most of the variance in the observed data. In other words, PCA projects the entire dataset onto a lower-dimensional subspace of different features where the principal components are the eigenvectors forming the axes. 

An important question is the number of principal components that are needed to describe the new feature subspace. A useful measure is the so-called "explained variance," which can be calculated from the eigenvalues and tells us how much information (variance) can be attributed to each of the principal components.


PCA is good for data visualisation and visualising groups of observations that may be gathered in different clusters (categorisation); however, the interpretability of the physical meaning of principal components may be a tradeoff. 

# Clustering

# Random forest decision trees




Traditional statistical learning 

Questions that may be answered by machine learning or deep learning methodologies 
Can clustering methodologies be used to down select a benchmarking suite ?
Can Principal Component Analysis be used to reveal big outliers and explain reasons for large biases ?
Can regression models or decision trees predict bias ?



Clustering does this without any prior knowledge of what these groups could or should look like. 

Two classical methods of clustering analysis are applied :
  
  * kmeans 
  * gower distance + PAM 
  
The first is suited for data sets which are numerical only. The second can deal with categorical variables and mixed type data.

## Machine Learning examples 

The `kmeans` function is part of the `stats` package which is by default in any R distribution. 

The typical methodology includes : 

  * determining the number of target groups or clusters
  * running the kmeans algorith to identigy group members

## Kmeans 

The function `plot_scree` will create a scree plot for determining the target number of groups. It uses the approach of optimizing the ration of the within groups sum of squares (wss) to the between groups sum of squares (bss) :  the sum, over all observations, of the squared differences of each observation from the overall group mean. 

$$
tss = \sum_{i=1}^n(y_i -\overline{y})
$$

## Clustering ICSBEP benchmarks based on sensitivity data 


## Prepping the data 

```{r, warning=FALSE, message=FALSE, eval=FALSE}

r<-filter(sendis, INST=="NRG", LIBVER=="JEFF-3.3", MODEL=="Only") %>%
  select(FULLID, SHORTID, CASETYPE, FISS, FORM, SPEC, EALF, CALCVAL, EXPVAL, RESIDUAL)%>%
  unique()

shortids<-r%>%select(FULLID, SHORTID)

mats<-fread("../data-raw/mats_used.csv")
mats<-mats%>%
  mutate(ISOTOPE=paste0(NAME,A))%>%
  select(-V1, -M2, -MAT, -M, -N)

s<-sens%>%
  mutate(IR = paste0(ISOTOPE, "_", REACTION))%>%
  merge(mats, by = "ISOTOPE")%>%
  merge(shortids)%>% ## add shortid column
  select(-FULLID)%>%
  na.omit()
 
# analysis is done on generic name df :
# keep onlu U-235 data and only KSENSTOT, spread by reaction : 
df<-filter(s, ISOTOPE%in%c("U235", "U238", "O16", "H1", "Fe56"))%>%
  select(-ISOTOPE, -KSENS1, -KSENS2, -KSENS3)%>%
  filter(REACTION == "nubar" | REACTION =="capture")


#df<-s%>%
#  select(-ISOTOPE, -KSENS1, -KSENS2, -KSENS3)%>%
#  filter(REACTION == "nubar" | REACTION =="capture")



# making long data wider : 
df<-df%>% 
  spread(key = IR, value= KSENSTOT)%>%
  select(-REACTION, -Z, -A, -NAME)%>%
  #na.omit()%>% #getrid of all remaining NA's
  unique() 

#replace all NA's with 0 : 
df[is.na(df)] <- 0

# Extremely important : group_by and summarize : 
df<-df %>% group_by(SHORTID) %>% summarise_all(funs(sum))

# use VIM::aggr to check consistency of data 
# aggr(df)

# prepping and SCALING data for analysis :  
df_sc<-df%>%
  merge(shortids)%>%
  select(-FULLID)

# for prcomp categorical variables cannot be used, passing SHORTID as rowname and scaling data :
rownames(df_sc)<-NULL
df_sc<-as.data.frame(df_sc%>%column_to_rownames(var = "SHORTID")%>%
  scale())

# 
# sub_df<-df_sc%>%select(-CLUSTER, -FULLID)
# rownames(sub_df)<-NULL
# sub_df<-sub_df%>%column_to_rownames(var = "SHORTID")

pca.out<-prcomp(df_sc, scale=TRUE, center = TRUE)
 
# test if rotation is done this way : 

df_rotated<-pca.out$rotation * df_sc 
colnames(df_rotated)[1:3] <-c("PC1", "PC2", "PC3")
df_rotated<-df_rotated%>%select(PC1, PC2, PC3)

df_rotated<-as.data.frame(pca.out$x)%>%
  mutate(SHORTID=rownames(.))%>%
  merge(r) 


plot_ly(df_rotated, x=~PC1, y=~PC2, color = ~FISS, alpha = 0.8)


# f<-fviz_pca_biplot(pca.out, label = "var", habillage = df_rotated$FISS)
# p<-ggplotly(f)
# p


```



## Training and test sets 

```{r, eval=FALSE}


# merge with residuals :
subdf<-df%>%
  merge(r)%>%
  filter(FISS=="LEU" | FISS=="HEU")%>% #restrict to subset
  mutate(DELTA=round((CALCVAL-EXPVAL),4)*1e+5)%>%
  select(-FULLID, -CASETYPE, -FISS, -FORM, -SPEC, -RESIDUAL, -CALCVAL, -DELTA)%>%
  column_to_rownames(var="SHORTID")

# df<-df%>%
#  filter(FISS=="LEU")

n <- nrow(subdf)
shuffled_df <- subdf[sample(n),]

fraction_training<-0.80
train_indices <- 1:round(fraction_training * n)
test_indices <- (round(fraction_training* n) + 1):n

train <- shuffled_df[train_indices, ]
test <- shuffled_df[test_indices, ]

# Fill in the model that has been learned.
tree <- rpart(EXPVAL~ ., data=train)

tree<-randomForest(EXPVAL~., data=train,
                      ntree = 5000, mtry = 7,
                      na.action = na.omit)

pred_tree<-predict(tree, test)
pred_df<-as.data.frame(pred_tree)
colnames(pred_df)<-c("PREDICTED")
pred_df<-pred_df%>%
  mutate(SHORTID=rownames(.))%>%
  select(SHORTID, PREDICTED)



#pred_rforest<-predict(rforest, test)

test<-test%>%
  mutate(SHORTID=rownames(.))

pred_df<-as.data.frame(pred_df)%>%
  merge(test)%>%
  mutate(
    RATIO=PREDICTED/EXPVAL,
    PCM_DIFF=(PREDICTED-EXPVAL)*1e+5
    )
  
# pred_rforest<-as.data.frame(pred_rforest)%>%
#   merge(test)%>%
#   mutate(PREDICTED=pred_rforest, 
#          RATIO= DELTA/PREDICTED)%>%
#   unique()


plot_ly(pred_df, x=~SHORTID, y=~EXPVAL, type = "scatter", mode="markers")%>%
  add_trace(y=~PREDICTED)

plot_ly(pred_df, x=~SHORTID, y=~PCM_DIFF, type = "scatter", mode="markers")

plot_ly(pred_df, x=~PCM_DIFF, type = "histogram")

#conf<-table(test$RESIDUAL, pred)

# accuracy of model 
# acc<- sum(diag(conf)) / sum(conf)
# acc

#fancyRpartPlot(pred_tree)

```

## SFCOMPO application

```{r, eval=FALSE}

sf<-fread("../data-raw/sfcompo2.csv", stringsAsFactors = TRUE)%>%
  select(
    # -"Reactor design",
    # -"Assembly identifier",
    # -"Rod identifier",
    -"Sample identifier",
    -'Concentration', #redundant
    -'Concentration Unit')%>%
  rename(RNAME = 'Reactor name',
         RTYPE = 'Reactor type',
         EBUP = 'Estimated burnup',
         EU235 = 'e. U235',
         EPU = 'e. Pu',
         EPUFISS = 'e. Pu239 + Pu241',
         SAMPLEID = 'SFCompo sample ref',
         MTYPE = 'Measurement type',
         ITEM = 'Item',
         VALUE = 'Value',
         VALUNIT = 'Unit',
         METHOD = 'Method',
         LAB = 'Laboratory'
         )



 sf<-cSplit(as.data.table(sf), "EBUP", " ")%>%
   rename(
     EBUPVAL  = EBUP_1,
     EBUPUNIT = EBUP_2
     ) 
 
sf<-cSplit(as.data.table(sf), "Uncertainty", " ")%>%
   rename(
     UNCERTAINTY = Uncertainty_1
     )%>%
  select(-Uncertainty_2)%>%
  mutate(VALERR = UNCERTAINTY/Sigma,
         UNCERTAINTY = NULL, 
         Sigma = NULL)%>%
  filter(!is.na(VALERR))
 
sf<-cSplit(as.data.table(sf), "EU235", " ")%>%
   rename(
     EU235  = EU235_1
     )%>%
  select(-EU235_2)

sf<-cSplit(as.data.table(sf), "EPU", " ")%>%
   rename(
     EPU  = EPU_1
     )%>%
  select(-EPU_2)

sf<-cSplit(as.data.table(sf), "EPUFISS", " ")%>%
   rename(
     EPUFISS  = EPUFISS_1
     )%>%
  select(-EPUFISS_2)

sf<-sf%>%
  select(
    SAMPLEID,
    RNAME,RTYPE,
    EU235,EPU,EPUFISS,
    EBUPVAL,EBUPUNIT,
    MTYPE, ITEM,
    Z,A,I,
    VALUE,VALUNIT,VALERR,
    METHOD, 
    LAB
    )%>%
  mutate(VALUE=as.numeric(VALUE))

# Getting rid of useless data and transformong to same units: 
 sf<-sf%>%
  filter(
    ITEM!="Burnup",
    EBUPUNIT!="MW*h/kgUi"
         )%>%
   mutate(
     EBUPVAL=ifelse(EBUPUNIT=='MW*d/tUi'  , EBUPVAL/1000,
              ifelse(EBUPUNIT=='MW*d/tHMi', EBUPVAL/1000, 
              EBUPVAL
     )))%>%
  rename(EBUP=EBUPVAL)%>%
  select(-EBUPUNIT) # ALL burnups now given in GWD/tHMi
   
summary(sf)

ics<-sf%>%filter(MTYPE=="Isotopic Concentration")
 
t<-fread('../data-raw/sfcompo_converted.csv', stringsAsFactors = TRUE, sep = ",")%>%
  select(-BupUnit,-'Assembly identifier', -'Rod identifier', 
         -'Sample identidier', -'Unit*')%>%
  rename(RNAME = 'Reactor name',
         RCODE = 'Reactor code',
         SAMPLEID = 'SFCompo sample ref',
         EBUP = 'Burnup',
         ITEM = 'Nuclide',
         VALUE = 'Concentration',
         VALUNIT = 'ConcUnit',
         CONCVAL = 'Concentration*'
         )

t<-cSplit(as.data.table(t), "Uncertainty", " ")%>%
   rename(
     UNCERTAINTY = Uncertainty_1
     )%>%
  select(-Uncertainty_2)%>%
  mutate(CONCERRPCT = UNCERTAINTY/Sigma,
         UNCERTAINTY = NULL, 
         Sigma = NULL)%>%
group_by(SAMPLEID, ITEM)%>%
  mutate(
    MVALUE=mean(CONCVAL),
    MERR=sqrt(mean((CONCERRPCT/100)^2*CONCVAL^2))
         )%>%
  select(-Z, -A, -I, -VALUE, -VALUNIT, -CONCVAL, -CONCERRPCT, -EBUP)%>%
  arrange(SAMPLEID, ITEM)%>%
  unique()

#make data long :
t<-t%>%
  spread(key = ITEM, value = MVALUE)%>%
  select(-RNAME,-RCODE, -MERR)%>%
  rename(
    Am0 = "Am (natural)",
    Cm0 = "Cm (natural)",
    Cs0 = "Cs (natural)",
    Eu0 = "Eu (natural)",
    Gd0 = "Gd (natural)",
    Nd0 = "Nd (natural)",
    Pu0 = "Pu (natural)",
    Sm0 = "Sm (natural)",
    U0 = "U (natural)" 
  )


# Extremely important : group_by and summarize : 
t[is.na(t)] <- 0
t<-t%>% group_by(SAMPLEID) %>% summarise_all(funs(sum))


samples_info<-sf%>%select(SAMPLEID, RNAME, RTYPE, starts_with("E"))%>%unique()
#replace all initial enrichment NA's with 0 : 
samples_info[is.na(samples_info)] <- 0

sf_data<-merge(t,samples_info)%>%
  select(-RNAME)%>%
  na.omit() #get rid of 12% of data without uncertainty :
 
head(sf_data)

# save to csv file : 
write_csv(sf_data, "../data-raw/sf_longdata.csv")

###################################################@@

## try random forest : 
 
subdf<-sf_data%>%
  select(-EPU, -EPUFISS, -EU235)

rownames(subdf)<-NULL

subdf<-subdf%>%
  column_to_rownames(var="SAMPLEID")

n <- nrow(subdf)
shuffled_df <- subdf[sample(n),]

fraction_training<-0.75
train_indices <- 1:round(fraction_training * n)
test_indices <- (round(fraction_training* n) + 1):n

train <- shuffled_df[train_indices, ]
test <- shuffled_df[test_indices, ]
  
tree<-randomForest(RTYPE~., data=train,
                      ntree = 5000, mtry =50,
                      na.action = na.omit)

pred_tree<-predict(tree, test)
summary(pred_tree)

conf<-table(test$RTYPE, pred_tree)
conf

acc<-sum(diag(conf))/sum(conf)
acc
 
## try predict EBUP : 

train<-train%>%select(-RTYPE)
test<-test%>%select(-RTYPE)
tree<-randomForest(EBUP~., data=train,
                      ntree = 5000, mtry =50,
                      na.action = na.omit)
pred_tree<-predict(tree, test)

test<-test%>%
  mutate(SAMPLEID=rownames(.))
  

pred_df<-as.data.frame(pred_tree)
colnames(pred_df)<-c("PREDICTED")
pred_df<-pred_df%>%
  mutate(SAMPLEID=rownames(.))%>%
  #merge(test, by=c('SAMPLEID'), all.x = TRUE, all.y = FALSE)%>%
  merge(samples_info, by=c('SAMPLEID'), all.x = TRUE, all.y = FALSE)%>%
  select(SAMPLEID, RNAME, RTYPE, EBUP, PREDICTED)%>%
  mutate(RATIO=PREDICTED/EBUP)
  

ggplot(pred_df, aes(x=SAMPLEID, y=RATIO, color=RTYPE))+
  geom_point()

```







 
## other techniques

```{r, eval=FALSE} 

# make scree plot to find out appropriate number of clusters 
# scree<-plot_scree(df_sc, cmax = 50, nstart=50)


df_sc<-data.frame(df_sc, "CLUSTER" = as.factor(km$cluster))
df<-data.frame(df, "CLUSTER" = as.factor(km$cluster))

# revert rownames to columns merge to get SHORTID : 
df_sc<-df_sc%>%mutate(FULLID=rownames(.))%>%
  merge(shortids)

# g<-ggplot(df, aes(x=EALF, y=RESIDUAL, color=CLUSTER))+
#   geom_point()+
#   theme_bw()




#p<-plot_ly(df, x=~U238_capture, y=~U235_capture, color=~CLUSTER, symbol = ~CASETYPE, text=~FULLID)
#p


#summary(pr.out)
# biplot(pr.out)

#kable(table(paste0(df$FISS,"-",df$SPEC), df$CLUSTER))

km<-kmeans(df_sc, centers = 4, nstart = 50)

```



## Regressions and predictions 

## For mixed data types : gower distance + PAM 
 
 

  
