<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Clustering • sendis</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/spacelab/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Clustering">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sendis</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/sendis.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/article1.html">Article 1</a>
    </li>
    <li>
      <a href="../articles/clustering.html">Clustering</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/fmichelsendis/sendis">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Clustering</h1>
            
            <h4 class="date">2018-12-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/fmichelsendis/sendis/blob/master/vignettes/clustering.Rmd"><code>vignettes/clustering.Rmd</code></a></small>
      <div class="hidden name"><code>clustering.Rmd</code></div>

    </div>

    
    
<div id="machine-learning-for-nuclear-data-analyses" class="section level2">
<h2 class="hasAnchor">
<a href="#machine-learning-for-nuclear-data-analyses" class="anchor"></a>Machine Learning for Nuclear Data Analyses</h2>
<p>Traditional statistical learning</p>
<p>Questions that may be answered by machine learning or deep learning methodologies Can clustering methodologies be used to down select a benchmarking suite ? Can Principal Component Analysis be used to reveal big outliers and explain reasons for large biases ? Can regression models or decision trees predict bias ?</p>
<p>Clustering does this without any prior knowledge of what these groups could or should look like.</p>
<p>Two classical methods of clustering analysis are applied :</p>
<ul>
<li>kmeans</li>
<li>gower distance + PAM</li>
</ul>
<p>The first is suited for data sets which are numerical only. The second can deal with categorical variables and mixed type data.</p>
</div>
<div id="machine-learning-examples" class="section level2">
<h2 class="hasAnchor">
<a href="#machine-learning-examples" class="anchor"></a>Machine Learning examples</h2>
<p>The <code>kmeans</code> function is part of the <code>stats</code> package which is by default in any R distribution.</p>
<p>The typical methodology includes :</p>
<ul>
<li>determining the number of target groups or clusters</li>
<li>running the kmeans algorith to identigy group members</li>
</ul>
</div>
<div id="kmeans" class="section level2">
<h2 class="hasAnchor">
<a href="#kmeans" class="anchor"></a>Kmeans</h2>
<p>The function <code>plot_scree</code> will create a scree plot for determining the target number of groups. It uses the approach of optimizing the ration of the within groups sum of squares (wss) to the between groups sum of squares (bss) : the sum, over all observations, of the squared differences of each observation from the overall group mean.</p>
<p><span class="math display">\[
tss = \sum_{i=1}^n(y_i -\overline{y})
\]</span></p>
</div>
<div id="clustering-icsbep-benchmarks-based-on-sensitivity-data" class="section level2">
<h2 class="hasAnchor">
<a href="#clustering-icsbep-benchmarks-based-on-sensitivity-data" class="anchor"></a>Clustering ICSBEP benchmarks based on sensitivity data</h2>
</div>
<div id="prepping-the-data" class="section level2">
<h2 class="hasAnchor">
<a href="#prepping-the-data" class="anchor"></a>Prepping the data</h2>
</div>
<div id="training-and-test-sets" class="section level2">
<h2 class="hasAnchor">
<a href="#training-and-test-sets" class="anchor"></a>Training and test sets</h2>
</div>
<div id="sfcompo-application" class="section level2">
<h2 class="hasAnchor">
<a href="#sfcompo-application" class="anchor"></a>SFCOMPO application</h2>
</div>
<div id="principal-component-analysis" class="section level2">
<h2 class="hasAnchor">
<a href="#principal-component-analysis" class="anchor"></a>Principal Component Analysis</h2>
<p>Observations and Features</p>
<p>Principal component analysis (PCA) are commonly used dimension reduction techniques that transform a collection of correlated variables into a smaller number of uncorrelated variables (or features) called principal components. Principal components (eigenvectors) are linear combinations of the original variables that account for most of the variance in the observed data. In other words, PCA projects the entire dataset onto a lower-dimensional subspace of different features where the eigenvectors will form the axes.</p>
<p>An important question is the number of principal components that are needed to describe the new feature subspace. A useful measure is the so-called “explained variance,” which can be calculated from the eigenvalues and tells us how much information (variance) can be attributed to each of the principal components.</p>
<p>Good for data visualisation and</p>
<p>Interpretability of physical meaning of principal components may be an issue.</p>
<div id="point-towards-the-culprit-which-pca-explains-the-residual" class="section level3">
<h3 class="hasAnchor">
<a href="#point-towards-the-culprit-which-pca-explains-the-residual" class="anchor"></a>point towards the culprit : which pca explains the residual ?</h3>
</div>
</div>
<div id="other-techniques" class="section level2">
<h2 class="hasAnchor">
<a href="#other-techniques" class="anchor"></a>other techniques</h2>
</div>
<div id="regressions-and-predictions" class="section level2">
<h2 class="hasAnchor">
<a href="#regressions-and-predictions" class="anchor"></a>Regressions and predictions</h2>
</div>
<div id="for-mixed-data-types-gower-distance-pam" class="section level2">
<h2 class="hasAnchor">
<a href="#for-mixed-data-types-gower-distance-pam" class="anchor"></a>For mixed data types : gower distance + PAM</h2>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#machine-learning-for-nuclear-data-analyses">Machine Learning for Nuclear Data Analyses</a></li>
      <li><a href="#machine-learning-examples">Machine Learning examples</a></li>
      <li><a href="#kmeans">Kmeans</a></li>
      <li><a href="#clustering-icsbep-benchmarks-based-on-sensitivity-data">Clustering ICSBEP benchmarks based on sensitivity data</a></li>
      <li><a href="#prepping-the-data">Prepping the data</a></li>
      <li><a href="#training-and-test-sets">Training and test sets</a></li>
      <li><a href="#sfcompo-application">SFCOMPO application</a></li>
      <li><a href="#principal-component-analysis">Principal Component Analysis</a></li>
      <li><a href="#other-techniques">other techniques</a></li>
      <li><a href="#regressions-and-predictions">Regressions and predictions</a></li>
      <li><a href="#for-mixed-data-types-gower-distance-pam">For mixed data types : gower distance + PAM</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="https:://www.sendis.org">Franco Michel-Sendis</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
